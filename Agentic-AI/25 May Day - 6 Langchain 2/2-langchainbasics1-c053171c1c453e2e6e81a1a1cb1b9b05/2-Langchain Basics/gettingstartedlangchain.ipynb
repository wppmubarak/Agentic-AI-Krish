{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ae95606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f3c76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dd7e631",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getenv(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a95342a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mGROQ_API_KEY\u001b[39m\u001b[33m\"\u001b[39m]=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mGROQ_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m## Langsmith Tracking And Tracing\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLANGCHAIN_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mLANGCHAIN_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mLANGCHAIN_PROJECT\u001b[39m\u001b[33m\"\u001b[39m]=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mLANGCHAIN_PROJECT\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mLANGCHAIN_TRACING_V2\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[33m\"\u001b[39m\u001b[33mtrue\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:722\u001b[39m, in \u001b[36m__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen os>:782\u001b[39m, in \u001b[36mcheck_str\u001b[39m\u001b[34m(value)\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: str expected, not NoneType"
     ]
    }
   ],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "## Langsmith Tracking And Tracing\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47124a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x0000019DD18CE7B0> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000019DD18CF230> root_client=<openai.OpenAI object at 0x0000019DD1765A90> root_async_client=<openai.AsyncOpenAI object at 0x0000019DD18CE900> model_name='o1-mini' temperature=1.0 model_kwargs={} openai_api_key=SecretStr('**********')\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"o1-mini\")\n",
    "print(llm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35ca146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='**Agentic AI** refers to artificial intelligence systems designed to act autonomously with a degree of agency, enabling them to make decisions, take actions, and pursue goals with minimal human intervention. The concept of agency in AI implies that these systems can understand their environment, set objectives, plan actions, and execute them effectively to achieve desired outcomes.\\n\\n### Key Characteristics of Agentic AI\\n\\n1. **Autonomy**: Agentic AI systems operate independently without continuous human oversight. They can initiate actions based on their programming and perception of their environment.\\n\\n2. **Goal-Oriented Behavior**: These AI systems have specific objectives or goals they aim to achieve. They can prioritize tasks and adjust their strategies to reach these goals efficiently.\\n\\n3. **Perception and Adaptation**: Agentic AI can perceive its environment through sensors or data inputs and adapt its behavior based on changing circumstances or new information.\\n\\n4. **Decision-Making**: They possess the ability to analyze data, evaluate options, and make informed decisions to guide their actions toward achieving goals.\\n\\n5. **Learning and Improvement**: Agentic AI systems often incorporate machine learning techniques, allowing them to learn from experiences and improve their performance over time.\\n\\n### Examples of Agentic AI\\n\\n1. **Autonomous Vehicles**: Self-driving cars like those developed by Tesla or Waymo showcase agentic AI by navigating roads, avoiding obstacles, and making real-time decisions to transport passengers safely.\\n\\n2. **Robotic Process Automation (RPA)**: Advanced robots in manufacturing or logistics that can perform tasks such as assembling products, managing inventory, or handling shipments with minimal human intervention.\\n\\n3. **Personal Assistants**: AI-driven personal assistants (e.g., advanced versions of Siri, Alexa, or Google Assistant) that can manage schedules, control smart home devices, and even initiate actions based on user preferences.\\n\\n4. **Autonomous Drones**: Drones used for delivery, surveillance, or agricultural monitoring that can plan their flight paths, avoid obstacles, and complete missions without direct human control.\\n\\n5. **Intelligent Agents in Software**: AI systems within software applications that can optimize workflows, manage resources, or provide personalized recommendations based on user behavior.\\n\\n### Applications of Agentic AI\\n\\n- **Healthcare**: Autonomous diagnostic systems that analyze medical data, identify patterns, and recommend treatments without constant input from healthcare professionals.\\n  \\n- **Finance**: Algorithmic trading systems that make investment decisions, execute trades, and manage portfolios autonomously based on market conditions.\\n\\n- **Customer Service**: Chatbots and virtual agents that handle customer inquiries, resolve issues, and improve their responses through interactions.\\n\\n- **Smart Cities**: AI systems that manage traffic flow, energy distribution, and public safety measures by making real-time decisions to enhance urban living.\\n\\n### Ethical and Societal Considerations\\n\\nThe development and deployment of agentic AI raise several ethical and societal issues:\\n\\n1. **Accountability**: Determining who is responsible for the actions of autonomous AI systems, especially in cases of errors or unintended consequences.\\n\\n2. **Bias and Fairness**: Ensuring that agentic AI systems make decisions free from biases present in their training data or algorithms, which could lead to unfair treatment of individuals or groups.\\n\\n3. **Privacy**: Protecting personal data that agentic AI systems may collect and analyze to make informed decisions.\\n\\n4. **Security**: Safeguarding autonomous AI systems from malicious attacks or manipulations that could lead to harmful actions.\\n\\n5. **Employment Impact**: Addressing the potential displacement of jobs due to automation and finding ways to integrate AI systems into the workforce responsibly.\\n\\n6. **Transparency**: Making the decision-making processes of agentic AI systems understandable to users and stakeholders to build trust and facilitate oversight.\\n\\n### Future Prospects\\n\\nAgentic AI continues to advance with ongoing research in areas like reinforcement learning, natural language processing, and computer vision. As these technologies evolve, agentic AI systems are expected to become more capable, adaptable, and integrated into various aspects of daily life and industry. However, balancing innovation with ethical considerations will be crucial to ensure that the benefits of agentic AI are realized while minimizing potential risks.\\n\\n### Conclusion\\n\\nAgentic AI represents a significant step towards more autonomous and intelligent systems capable of performing complex tasks with minimal human intervention. By embodying characteristics such as autonomy, goal orientation, and adaptability, agentic AI has the potential to transform numerous industries and aspects of society. However, it also necessitates careful consideration of ethical, legal, and societal implications to ensure its responsible and beneficial deployment.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 994, 'prompt_tokens': 13, 'total_tokens': 1007, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'o1-mini-2024-09-12', 'system_fingerprint': 'fp_7989eaacf6', 'id': 'chatcmpl-BaZwzyfp1jjXE6sYxDSurcO3zweZU', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--64f30753-ef45-42a5-9a7b-d3f67281c05f-0' usage_metadata={'input_tokens': 13, 'output_tokens': 994, 'total_tokens': 1007, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}\n"
     ]
    }
   ],
   "source": [
    "result=llm.invoke(\"What is Agentic AI\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41d6b3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Agentic AI** refers to artificial intelligence systems designed to act autonomously with a degree of agency, enabling them to make decisions, take actions, and pursue goals with minimal human intervention. The concept of agency in AI implies that these systems can understand their environment, set objectives, plan actions, and execute them effectively to achieve desired outcomes.\n",
      "\n",
      "### Key Characteristics of Agentic AI\n",
      "\n",
      "1. **Autonomy**: Agentic AI systems operate independently without continuous human oversight. They can initiate actions based on their programming and perception of their environment.\n",
      "\n",
      "2. **Goal-Oriented Behavior**: These AI systems have specific objectives or goals they aim to achieve. They can prioritize tasks and adjust their strategies to reach these goals efficiently.\n",
      "\n",
      "3. **Perception and Adaptation**: Agentic AI can perceive its environment through sensors or data inputs and adapt its behavior based on changing circumstances or new information.\n",
      "\n",
      "4. **Decision-Making**: They possess the ability to analyze data, evaluate options, and make informed decisions to guide their actions toward achieving goals.\n",
      "\n",
      "5. **Learning and Improvement**: Agentic AI systems often incorporate machine learning techniques, allowing them to learn from experiences and improve their performance over time.\n",
      "\n",
      "### Examples of Agentic AI\n",
      "\n",
      "1. **Autonomous Vehicles**: Self-driving cars like those developed by Tesla or Waymo showcase agentic AI by navigating roads, avoiding obstacles, and making real-time decisions to transport passengers safely.\n",
      "\n",
      "2. **Robotic Process Automation (RPA)**: Advanced robots in manufacturing or logistics that can perform tasks such as assembling products, managing inventory, or handling shipments with minimal human intervention.\n",
      "\n",
      "3. **Personal Assistants**: AI-driven personal assistants (e.g., advanced versions of Siri, Alexa, or Google Assistant) that can manage schedules, control smart home devices, and even initiate actions based on user preferences.\n",
      "\n",
      "4. **Autonomous Drones**: Drones used for delivery, surveillance, or agricultural monitoring that can plan their flight paths, avoid obstacles, and complete missions without direct human control.\n",
      "\n",
      "5. **Intelligent Agents in Software**: AI systems within software applications that can optimize workflows, manage resources, or provide personalized recommendations based on user behavior.\n",
      "\n",
      "### Applications of Agentic AI\n",
      "\n",
      "- **Healthcare**: Autonomous diagnostic systems that analyze medical data, identify patterns, and recommend treatments without constant input from healthcare professionals.\n",
      "  \n",
      "- **Finance**: Algorithmic trading systems that make investment decisions, execute trades, and manage portfolios autonomously based on market conditions.\n",
      "\n",
      "- **Customer Service**: Chatbots and virtual agents that handle customer inquiries, resolve issues, and improve their responses through interactions.\n",
      "\n",
      "- **Smart Cities**: AI systems that manage traffic flow, energy distribution, and public safety measures by making real-time decisions to enhance urban living.\n",
      "\n",
      "### Ethical and Societal Considerations\n",
      "\n",
      "The development and deployment of agentic AI raise several ethical and societal issues:\n",
      "\n",
      "1. **Accountability**: Determining who is responsible for the actions of autonomous AI systems, especially in cases of errors or unintended consequences.\n",
      "\n",
      "2. **Bias and Fairness**: Ensuring that agentic AI systems make decisions free from biases present in their training data or algorithms, which could lead to unfair treatment of individuals or groups.\n",
      "\n",
      "3. **Privacy**: Protecting personal data that agentic AI systems may collect and analyze to make informed decisions.\n",
      "\n",
      "4. **Security**: Safeguarding autonomous AI systems from malicious attacks or manipulations that could lead to harmful actions.\n",
      "\n",
      "5. **Employment Impact**: Addressing the potential displacement of jobs due to automation and finding ways to integrate AI systems into the workforce responsibly.\n",
      "\n",
      "6. **Transparency**: Making the decision-making processes of agentic AI systems understandable to users and stakeholders to build trust and facilitate oversight.\n",
      "\n",
      "### Future Prospects\n",
      "\n",
      "Agentic AI continues to advance with ongoing research in areas like reinforcement learning, natural language processing, and computer vision. As these technologies evolve, agentic AI systems are expected to become more capable, adaptable, and integrated into various aspects of daily life and industry. However, balancing innovation with ethical considerations will be crucial to ensure that the benefits of agentic AI are realized while minimizing potential risks.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Agentic AI represents a significant step towards more autonomous and intelligent systems capable of performing complex tasks with minimal human intervention. By embodying characteristics such as autonomy, goal orientation, and adaptability, agentic AI has the potential to transform numerous industries and aspects of society. However, it also necessitates careful consideration of ethical, legal, and societal implications to ensure its responsible and beneficial deployment.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8357dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n<think>\\nOkay, the user said \"Hi My name is Krish.\" I should respond in a friendly way. Let me start by greeting them back. Maybe say something like \"Hello Krish!\" to acknowledge their name. Then, I can offer assistance. I should ask how I can help them today. Keep it open-ended so they can ask anything they need. Let me check for typos. Hmm, maybe add an emoji to keep it warm. Yep, that should work.\\n</think>\\n\\nHello Krish! 😊 How can I assist you today? Feel free to ask me anything!', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 116, 'prompt_tokens': 15, 'total_tokens': 131, 'completion_time': 0.264764411, 'prompt_time': 0.002742108, 'queue_time': 0.26895347199999997, 'total_time': 0.267506519}, 'model_name': 'qwen-qwq-32b', 'system_fingerprint': 'fp_28178d7ff6', 'finish_reason': 'stop', 'logprobs': None}, id='run--511035c6-a436-4add-897f-565a9130ad72-0', usage_metadata={'input_tokens': 15, 'output_tokens': 116, 'total_tokens': 131})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"qwen-qwq-32b\")\n",
    "model.invoke(\"Hi My name is Krish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88e170b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer. Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d414adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000019DE3B4DD10>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000019DE3B4E850>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model=ChatGroq(model=\"gemma2-9b-it\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d40b1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer. Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x0000019DE3B4DD10>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x0000019DE3B4E850>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### chaining\n",
    "chain=prompt|model\n",
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a293571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As an AI engineer, I'm familiar with LangSmith. It's an open-source platform designed to simplify the process of building and deploying large language models (LLMs). \n",
      "\n",
      "Here's a breakdown of what makes LangSmith noteworthy:\n",
      "\n",
      "**Key Features:**\n",
      "\n",
      "* **User-Friendly Interface:** LangSmith boasts a web-based interface, making it accessible to a wider range of users, even those without extensive coding experience.\n",
      "* **Modular Design:** The platform is built with modularity in mind, allowing users to easily combine and customize different components to suit their specific needs.\n",
      "* **Fine-Tuning Capabilities:** LangSmith provides tools for fine-tuning pre-trained LLMs on custom datasets, enabling users to tailor models for specific tasks or domains.\n",
      "* **Experiment Tracking:** It includes features for tracking experiments and comparing different model configurations, facilitating the iterative development process.\n",
      "* **Community Driven:** Being open-source, LangSmith benefits from a vibrant community of developers and researchers who contribute to its growth and improvement.\n",
      "\n",
      "**Benefits:**\n",
      "\n",
      "* **Lower Barrier to Entry:** LangSmith democratizes access to LLM development by providing a more accessible and user-friendly platform.\n",
      "* **Increased Efficiency:** Its modular design and automation features streamline the development workflow, saving time and effort.\n",
      "* **Customization and Flexibility:** Users can fine-tune models and tailor them to their specific use cases, achieving better performance and accuracy.\n",
      "* **Collaboration and Innovation:** The open-source nature fosters collaboration and encourages the sharing of knowledge and best practices.\n",
      "\n",
      "**Use Cases:**\n",
      "\n",
      "LangSmith finds applications in various domains, including:\n",
      "\n",
      "* **Chatbots and Conversational AI:**\n",
      "\n",
      "Developing customized chatbots for customer service, education, or entertainment.\n",
      "* **Text Generation:**\n",
      "\n",
      "Creating compelling content, such as articles, stories, or marketing copy.\n",
      "* **Language Translation:**\n",
      "\n",
      "Fine-tuning models for accurate and efficient language translation.\n",
      "* **Code Generation:**\n",
      "\n",
      "Assisting developers in generating code snippets or completing code tasks.\n",
      "\n",
      "**Overall, LangSmith is a powerful and versatile platform that empowers individuals and organizations to leverage the potential of LLMs for a wide range of applications.**\n",
      "\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about LangSmith or LLMs in general!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response=chain.invoke({\"input\":\"Can you tell me something about Langsmith\"})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6694a12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's talk about Langsmith! \n",
      "\n",
      "**Langsmith** is an open-source, community-driven platform designed to streamline the process of building, evaluating, and deploying large language models (LLMs). It's a powerful toolset that empowers developers and researchers to work with LLMs more efficiently and effectively.\n",
      "\n",
      "**Here's a breakdown of its key features and benefits:**\n",
      "\n",
      "* **Simplified LLM Development:**\n",
      "\n",
      "Langsmith provides a user-friendly interface and pre-built components that simplify the complexities of LLM development. This makes it accessible to a wider range of users, including those without extensive machine learning expertise.\n",
      "\n",
      "* **Streamlined Training and Evaluation:** The platform offers tools for efficient training, fine-tuning, and evaluating LLMs. It integrates with popular deep learning frameworks like PyTorch and TensorFlow, allowing you to leverage existing infrastructure and expertise.\n",
      "\n",
      "* **Collaborative Ecosystem:** Langsmith fosters a collaborative environment where developers can share models, datasets, and best practices. This open-source nature promotes innovation and accelerates progress in the field of LLMs.\n",
      "\n",
      "* **Model Deployment and Management:** The platform assists in deploying trained LLMs to various environments, including cloud platforms and local servers. It also provides tools for monitoring and managing deployed models, ensuring their optimal performance.\n",
      "\n",
      "* **Focus on Ethical Considerations:** Langsmith emphasizes responsible AI development by incorporating guidelines and best practices for mitigating bias, ensuring fairness, and promoting transparency in LLM development.\n",
      "\n",
      "**Who Benefits from Langsmith?**\n",
      "\n",
      "* **Researchers:**\n",
      "\n",
      "Langsmith empowers researchers to experiment with new LLM architectures, explore different training techniques, and accelerate their research endeavors.\n",
      "* **Developers:**\n",
      "\n",
      "Developers can leverage Langsmith to build LLM-powered applications, integrate LLMs into existing systems, and create innovative solutions across various domains.\n",
      "* **Data Scientists:** Langsmith provides data scientists with tools to analyze and understand the behavior of LLMs, contributing to the advancement of natural language processing research.\n",
      "\n",
      "**In Essence:**\n",
      "\n",
      "Langsmith is a comprehensive platform that democratizes access to LLM technology, making it easier for individuals and organizations to explore, develop, and deploy powerful AI solutions.\n",
      "\n",
      "\n",
      "Let me know if you have any more questions about Langsmith or LLMs in general. I'm here to help!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser=StrOutputParser()\n",
    "\n",
    "chain=prompt|model|output_parser\n",
    "\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0221a0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66da8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=JsonOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fe079e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'Return a JSON object.'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "52a5b27c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Langsmith', 'description': 'Langsmith is a powerful open-source platform for building and deploying AI assistants.', 'key_features': ['Allows developers to fine-tune pre-trained language models for specific tasks.', 'Provides a user-friendly interface for interacting with and managing AI assistants.', 'Offers a variety of tools and resources for building and deploying AI applications.', 'Built on a modular architecture, allowing for customization and extensibility.', 'Open-source and community-driven, fostering collaboration and innovation.'], 'website': 'https://www.langsmith.com/'}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ee96082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Assisgnment ---Chatprompttemplate\n",
    "\n",
    "### Prompt Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.Provide the response in json.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ed7d7e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': \"Langsmith is an open-source platform created by the team at Cohere designed to simplify the process of building and deploying custom AI applications.  \\n\\nHere are some key things to know about Langsmith:\\n\\n* **Focus on User Experience:** Langsmith prioritizes making AI development accessible to a wider audience, even those without extensive coding experience.\\n\\n* **Modular and Customizable:** It offers a modular architecture that allows users to easily integrate different AI models, tools, and components to create tailored solutions.\\n* **Streamlined Workflow:** Langsmith streamlines the development workflow by providing intuitive interfaces for tasks like data preparation, model training, and model deployment.\\n* **Emphasis on Collaboration:**  The platform encourages collaboration through features that enable teams to work together on AI projects.\\n* **Open Source:**  Being open-source, Langsmith fosters community contributions, transparency, and the ability to adapt the platform to specific needs.\\n\\n**Key Features:**\\n\\n* **Model Hub:** A repository of pre-trained AI models from various providers, including Cohere's own models.\\n* **Data Playground:** A space for cleaning, transforming, and visualizing data used for training AI models.\\n* **Experiment Tracker:**  Tools to track and compare the performance of different AI models and training configurations.\\n* **Deployment Tools:**  Options for deploying trained models as APIs or web applications.\\n\\n**Benefits:**\\n\\n* **Reduced Development Time:**  Langsmith's streamlined workflow and pre-built components accelerate the development process.\\n* **Improved Accessibility:**  The platform lowers the barrier to entry for individuals and teams new to AI development.\\n* **Increased Flexibility:**  The modular design allows for customization and the integration of various AI technologies.\\n\\n**Getting Started:**\\n\\nYou can find more information about Langsmith, including documentation, tutorials, and community resources, on the official Cohere website or their GitHub repository.\"}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model|output_parser\n",
    "response=chain.invoke({\"input\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50822936",
   "metadata": {},
   "source": [
    "### Assigments: https://python.langchain.com/docs/how_to/#prompt-templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c1c1802",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "output_parser=XMLOutputParser()\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an expert AI Engineer.<response><answer>Your answer here</answer></response>.Provide me answer based on the question\"),\n",
    "        (\"user\",\"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0ca6e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['query'], input_types={}, partial_variables={'format_instruction': 'The output should be formatted as a XML file.\\n1. Output should conform to the tags below.\\n2. If tags are not given, make them on your own.\\n3. Remember to always open and close all the tags.\\n\\nAs an example, for the tags [\"foo\", \"bar\", \"baz\"]:\\n1. String \"<foo>\\n   <bar>\\n      <baz></baz>\\n   </bar>\\n</foo>\" is a well-formatted instance of the schema.\\n2. String \"<foo>\\n   <bar>\\n   </foo>\" is a badly-formatted instance.\\n3. String \"<foo>\\n   <tag>\\n   </tag>\\n</foo>\" is a badly-formatted instance.\\n\\nHere are the output tags:\\n```\\nNone\\n```'}, template='Answer the user query \\n {format_instruction}\\n {query}\\n ')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### OutputParser\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "output_parser=XMLOutputParser()\n",
    "\n",
    "prompt=PromptTemplate(\n",
    "    template=\"Answer the user query \\n {format_instruction}\\n {query}\\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()},\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "940f704a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response>\\n  <model>Langsmith</model>\\n  <description>Langsmith is an open-source platform for building and deploying AI applications. It provides a framework for developing, training, and evaluating language models, as well as tools for deploying them in production.</description>\\n  <features>\\n    <feature>Modular design</feature>\\n    <feature>Support for multiple programming languages</feature>\\n    <feature>Easy integration with existing tools</feature>\\n    <feature>Open-source and community-driven</feature>\\n  </features>\\n  <website>https://www.langsmith.ai/</website>\\n</response> \\n\\n\\n' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 144, 'prompt_tokens': 195, 'total_tokens': 339, 'completion_time': 0.261818182, 'prompt_time': 0.009446571, 'queue_time': 0.246504287, 'total_time': 0.271264753}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--0bde4c43-4268-4beb-b4c4-aa3a32f86747-0' usage_metadata={'input_tokens': 195, 'output_tokens': 144, 'total_tokens': 339}\n"
     ]
    }
   ],
   "source": [
    "chain=prompt|model\n",
    "response=chain.invoke({\"query\":\"Can you tell me about Langsmith?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1eec50bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='<response><answer>LangChain is an open-source framework designed to simplify the development of applications powered by large language models (LLMs). It provides tools and components to streamline the process of integrating LLMs into various applications, such as chatbots, question-answering systems, and text summarizers. </answer></response>' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 39, 'total_tokens': 108, 'completion_time': 0.125454545, 'prompt_time': 0.003350234, 'queue_time': 0.243215077, 'total_time': 0.128804779}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None} id='run--0d9d3374-01e5-4474-b3a2-e9963c5226b6-0' usage_metadata={'input_tokens': 39, 'output_tokens': 69, 'total_tokens': 108}\n"
     ]
    }
   ],
   "source": [
    "##output parser\n",
    "#from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain.output_parsers.xml import XMLOutputParser\n",
    "\n",
    "# XML Output Parser\n",
    "output_parser = XMLOutputParser()\n",
    "\n",
    "# Prompt that instructs the model to return XML\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Respond in this XML format: <response><answer>Your answer here</answer></response>\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Build the chain\n",
    "chain = prompt | model\n",
    "\n",
    "# Run the chain\n",
    "#response = chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "raw_output =chain.invoke({\"input\": \"What is LangChain?\"})\n",
    "\n",
    "# Print result\n",
    "print(raw_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab7431f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'Because it was two tired!'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## With Pydantic\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "model = ChatOpenAI(temperature=0.7)\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "36e1dcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'joke': 'Why did the scarecrow win an award? Because he was outstanding in his field!'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Without Pydantic\n",
    "joke_query = \"Tell me a joke .\"\n",
    "\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f2ec0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<movie>Big</movie>\n",
      "<movie>Saving Private Ryan</movie>\n",
      "<movie>Forrest Gump</movie>\n",
      "<movie>Cast Away</movie>\n",
      "<movie>Philadelphia</movie>\n",
      "<movie>Apollo 13</movie>\n",
      "<movie>The Green Mile</movie>\n",
      "<movie>Sully</movie>\n",
      "<movie>Toy Story</movie>\n",
      "<movie>Sleepless in Seattle</movie>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.output_parsers import XMLOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "actor_query = \"Generate the shortened filmography for Tom Hanks.\"\n",
    "\n",
    "output = model.invoke(\n",
    "    f\"\"\"{actor_query}\n",
    "Please enclose the movies in <movie></movie> tags\"\"\"\n",
    ")\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c90caccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup=\"Why don't scientists trust atoms?\", punchline='Because they make up everything!')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import YamlOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0.5)\n",
    "\n",
    "# And a query intented to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = YamlOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | model | parser\n",
    "\n",
    "chain.invoke({\"query\": joke_query})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfed2d4",
   "metadata": {},
   "source": [
    "### Assisgment:\n",
    "Create a simple assistant that uses any LLM and should be pydantic, when we ask about any product it should give you two information product Name, product details tentative price in USD (integer). use chat Prompt Template.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2999f98",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_2_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
